# Diffusionモデル 基礎の基礎

## 1. はじめに

### 1.1 Diffusionモデルとは

**Diffusionモデル**は、**近年目覚ましい発展を遂げている画像生成AIの中核技術**です。これは**データにノイズを徐々に加えていき、そのノイズを除去する過程を学習することで、高品質なデータを生成する深層学習モデルの一種**です。

画像生成AIの基盤技術として注目されており、Stable Diffusionなどの最先端のAIサービスにも活用されています。

### 1.2 なぜ注目されているのか

Diffusionモデルが注目される主な理由は、**生成されるデータの質の高さと、学習の安定性、そして多様性**にあります。

従来の生成モデルでは、学習が不安定になったり、生成されるデータの種類が限られたりする問題がありました。Diffusionモデルはこれらの問題を克服し、より高品質で多様なデータを生成できるため、画像生成や音声生成、自然言語処理など、幅広い分野での応用が期待されています。

## 2. Diffusionモデルの基本的な仕組み

Diffusionモデルの基本的な仕組みは、**「拡散過程」と「逆拡散過程」の2つの主要なプロセス**によって成り立っています。

### 2.1 順方向拡散過程 (Forward Process)

順方向拡散過程とは、**元のデータに徐々にノイズを加えていくプロセス**です。具体的には、ガウスノイズと呼ばれるノイズを少しずつ加えていきます。このプロセスを繰り返すことで、最終的には元のデータの特徴が完全に失われ、純粋なノイズデータに変換されます。これは、きれいな写真に徐々に霧がかかり、だんだん何も見えなくなっていくような過程としてイメージできます。

この過程は、マルコフ連鎖と呼ばれる確率モデルで記述可能です。ソース によると、元のデータ $\mathbf{x}_0$ にステップサイズ $\{\beta_t \in (0, 1)\}_{t=1}^T$ によって制御される小さなガウスノイズを $T$ ステップで加えていき、ノイズ付きサンプル $\mathbf{x}_1, \dots, \mathbf{x}_T$ を生成します。最終的に $T \to \infty$ のとき、$\mathbf{x}_T$ は等方性ガウス分布と同等になります。論文 には、顔画像 $\mathbf{x}_0$ が最終的に完全なノイズ $\mathbf{x}_T$ になる図が示されています。

### 2.2 逆方向拡散過程 (Reverse Process)

逆方向拡散過程は、**順方向拡散過程で生成されたノイズから、元のデータを復元するプロセス**です。このプロセスでは、Diffusionモデルはノイズを少しずつ除去する方法を学習します。学習には、順方向拡散過程で加えられたノイズの情報を利用します。この逆方向拡散過程を繰り返すことで、最終的にはノイズから元のデータ、または元データに非常に近いデータを生成可能です。これは、完全にノイズ状態の画像から徐々に「花」や「山」などの特徴が現れ、最終的に鮮明な風景写真に復元されるような感覚です。

ソース によると、この逆方向プロセス $q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)$ からサンプリングできれば、ガウスノイズ入力 $\mathbf{x}_T$ から真のサンプルを再構築できます。ただし、 $q(\mathbf{x}_{t-1} \vert \mathbf{x}_t)$ を直接推定するのは難しいため、**モデル $p_\theta$ を学習してこれらの条件付き確率を近似**します。DDPMでは、この逆拡散過程はマルコフ連鎖として定義されます。

## 3. 他の生成モデルとの比較

Diffusionモデルは、GAN、VAE、Flow-based modelsといった他の生成モデルと比較されます。

### 3.1 GAN（敵対的生成ネットワーク）との違い

GANは、生成器と識別器の2つのネットワークを競わせることで高品質なデータを生成するモデルです。

Diffusionモデルは、**GANと比較して学習が安定しており、多様なデータを生成できるというメリットがあります**。ソース では、GANの訓練の不安定性が拡散モデルで解決されたと述べられています。

一方、GANは、**生成速度が速い**というメリットがあります。拡散モデルは、ノイズを少しずつ除去していくため、GANと比べて生成速度が遅いという課題があります。

### 3.2 VAE（変分オートエンコーダ）との違い

VAEは、潜在空間を介してデータを生成するモデルです。

Diffusionモデルは、**VAEと比較して、生成されるデータの品質が高い**という特徴があります。VAEは潜在空間の構造を利用してデータの意味的な特徴を捉えられますが、Diffusionモデルはより多様なデータを生成できるため、クリエイティブな用途に適しています。VAEとDiffusionモデルは、順方向プロセスと逆方向プロセス（またはスコア関数）の関係をVAEの変分オートエンコーダとして見ることができます。

### 3.3 Flow-based modelsとの違い

Flow-based modelsは、可逆な変換を用いてデータを生成するモデルです。データの確率密度を正確に計算できるため、異常検知などのタスクに適しています。

Diffusionモデルは、Flow-based modelsと比較して、**生成されるデータの多様性が高いのが特徴**です。拡散モデルは生成品質と多様性において優れているため、画像生成などの分野で広く利用されています。ソース では、2018年以降にFlowモデルの研究が進み、確率密度関数の変換を利用してデータを生成する手法であると説明されています。

## 4. Diffusionモデルの種類

拡散モデルにはいくつかの種類が存在し、それぞれ異なる特性を持っています。代表的なものとして以下の4つがあります。

### 4.1 DDPM (Denoising Diffusion Probabilistic Models)

**DDPM**は、**拡散モデルの基本的な枠組みを提供するモデル**です。Jonathan Hoらによって発表されました。順方向拡散過程で徐々にノイズを加え、逆方向拡散過程でノイズを除去する過程を学習します。学習の安定性と生成品質の高さから、多くの拡散モデルの基礎となっています。特に高品質な画像生成において優れた性能を発揮します。

### 4.2 DDIM (Denoising Diffusion Implicit Models)

**DDIM**は、**DDPMを改良したモデルで、より高速なサンプリングを可能**にしています。DDPMでは逆方向拡散過程で多くのステップを必要としますが、DDIMはより少ないステップで高品質なデータを生成可能です。また、生成過程をより細かく制御できるという特徴も持っています。DDIMのサンプリングプロセスは決定論的であり、これにより同じ潜在変数で生成された複数のサンプルは類似した高レベルの特徴を持つ「一貫性」の特性を持ちます。

### 4.3 SDE (Stochastic Differential Equation)

**SDE**は、**拡散過程を確率微分方程式で記述するモデル**です。DDPMやDDIMが離散的な時間ステップで拡散過程をモデル化するのに対し、SDEは連続的な時間でモデル化します。これにより、より柔軟なモデリングが可能になり、多様なデータ生成に対応できます。SDEは、物理現象のシミュレーションなど、より複雑なデータ生成タスクに応用されています。

### 4.4 ODE (Ordinary Differential Equation)

**ODE**は、**拡散過程を常微分方程式で記述するモデルであり、SDEの一種**です。SDEが確率的な揺らぎを含むのに対し、ODEは決定論的な過程としてモデル化します。計算効率が良いという特徴があり、高速なデータ生成が求められる場面で有効です。ODEは、リアルタイムでの画像生成などへの応用が期待されています。多くの推論（サンプリング）は、対応するODEとして解かれています。ODEベースで考える学習手法も多く出てきており、特にRectified Flowはデータとノイズの効率的な輸送を考え、少ないステップで良い精度の画像生成を可能にします。

## 5. Diffusionモデルの学習

### 5.1 損失関数

DDPMベースの拡散モデルの学習では、順方向プロセス $q$ と逆方向プロセス $p_{\theta}$ の関係をVAEとして捉え、各ステップの損失 $L_t$ はELBO（変分下限）を最大化することで求められます。最終的には、$q$ と $p_{\theta}$ の正規分布のKLダイバージェンスの最小化として扱うことができます。Hoら (2020) は、重み付け項を無視した単純化された目的関数でも学習がうまくいくことを発見しました。

### 5.2 ノイズ予測モデルのアーキテクチャ

Diffusionモデルでは、**画像 $x_t$ とタイムステップ $t$ を入力として、予測されるノイズを出力するニューラルネットワーク**を使用します。入力と出力が画像であるため、**U-Net**のようなAutoEncoderベースのアーキテクチャが一般的に用いられます。ただし、オリジナルのU-Netに改良が加えられることもあります。

最近では、画像の特徴を低次元の潜在空間に変換し、その潜在空間で拡散過程を行う**Latent Diffusion Model (LDM)**が登場し、計算コストを削減しています。LDMでは、学習された潜在空間で拡散およびノイズ除去プロセスが行われます。

また、U-Netに代わって**Transformerベースのアーキテクチャ（Diffusion Transformer: DiT）**も使用されるようになってきています。Transformerはスケーラビリティに優れている点が利点として挙げられます。

## 6. Diffusionモデルの利点と欠点

### 6.1 利点

*   **高品質な画像生成**: 写実的かつ細部まで鮮明でリアルな画像を生成可能です。
*   **学習の安定性**: 従来のGANなどで問題であった訓練の不安定性を解決しています。
*   **多様性**: ランダムなノイズからスタートするため、毎回異なる結果が得られ、多様なデータを生成できます。
*   **トラクタビリティと柔軟性**: 解析的に扱いやすく（トラクタビリティ）、多様なデータの構造を捉える柔軟性も持ち合わせています。

### 6.2 欠点

*   **計算コストが高い**: 特に高解像度画像の生成には大きな計算リソースが必要です。
*   **生成速度が遅い**: サンプル生成に多数のステップを要するため、GANなどと比較して生成に時間がかかります。
*   **学習データの質に依存**: 高品質なデータを生成するためには、大量の高品質な学習データを用意する必要があり、データの質に大きく依存します。

## 7. 応用例

Diffusionモデルは、その高い生成能力から、さまざまな分野で応用されています。

*   **画像生成 (Text-to-Image)**: テキストによる指示（プロンプト）を入力することで、高品質な画像を生成できます。**Stable Diffusion** (LDMベース)、**DALL-E 3**、**Imagen** などが有名です。
*   **画像修復**: 画像の一部が欠損したりノイズが混入したりした場合に、その部分を復元する技術です。
*   **超解像**: 低解像度の画像から高解像度の画像を生成する技術で、ノイズ除去の過程で画像の細部を復元できます。
*   **画像編集**: 画像の特定の部分を編集したり、新しい要素を追加したりすることに応用されています。
*   **動画生成**: 2D画像の生成技術を動画生成にも応用可能です。OpenAIのSoraなどが例として挙げられます。
*   **テキスト/コード生成**: 画像や動画だけでなく、テキストやコードの生成にも拡散モデルが応用されています。Google DeepMindの**Gemini Diffusion**は、テキストやコードを高速に生成する拡散モデルです。
*   **セマンティック・セグメンテーション**: 画像内の各ピクセルをその表す物体や領域に割り当てるタスクです。Diffusionモデルを導入することで、このタスクの精度を向上させる研究も行われています。

## 8. 今後の展望

Diffusionモデルの課題である生成速度の遅さや計算コストの高さに対して、様々な高速化手法が研究されています。**Progressive Distillation** や **Consistency Models** などが提案されています。**Latent Diffusion Models (LDM)**も、処理を潜在空間で行うことで計算効率を高めるアプローチです。

モデルアーキテクチャとしては、Transformerベースの研究が盛んに行われています。また、ODEベースの手法も注目されており、ゼロから高速モデルを学習可能になることが予想されています。

今後は、画像以外の様々なモダリティ（音声、文章など）への応用が拡大し、**大規模なデータセットで事前学習された汎用的な「基盤モデル」の一種**として、Diffusionモデルがさらに重要な役割を担っていくと考えられます。
